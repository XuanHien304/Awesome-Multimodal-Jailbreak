# Awesome-Jailbreak-against-Multimodal-Generative-Models

# Awesome Papers

# Related Survey
|  Title  |   Venue  |   Date   |   Code   | Taxonomy |
|:--------|:--------:|:--------:|:--------:|:--------:|
|[**A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends**](https://arxiv.org/pdf/2407.07403) | Arxiv | 2024 | [Github](https://github.com/liudaizong/Awesome-LVLM-Attack) | MLLM |

# Attack Bench of Multimodal Generative Models
|  Title  |   Venue  |   Date   |   Code   | Taxonomy |
|:--------|:--------:|:--------:|:--------:|:--------:|


## Jailbreak Attack of Multimodal LLM-based Models
|  Title  |   Venue  |   Date   |   Code   | Taxonomy |
|:--------|:--------:|:--------:|:--------:|:--------:|
|[**Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models**](https://openreview.net/forum?id=plmBsXHxgR&trk=public_post_comment-text) | ICLR 2024 Spotlight | 2024/01/16 | [Github](https://github.com/erfanshayegani/Jailbreak-In-Pieces) | Encoder Level |
|[**MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models**](https://arxiv.org/abs/2311.09127) | ECCV 2024 | 2024/11/29 | None | Encoder Level |
|[**FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts**](https://arxiv.org/abs/2311.05608) | Arxiv 2023 | 2023/11/09 | [Github](https://github.com/ThuCCSLab/FigStep) | Encoder Level |
|[**Jailbreaking Attack against Multimodal Large Language Model**](https://arxiv.org/abs/2402.02309) | Arxiv 2024 | 2024/02/04 | None| Encoder Level |
|[**Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models**](https://arxiv.org/abs/2403.09792) | ECCV 2024 | 2024 | [Github](https://github.com/RUCAIBox/HADES)| Encoder Level |
|[**Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character**](https://arxiv.org/abs/2405.20773) | Arxiv 2024 | 2024/02/13 | None | Encoder Level |
|[**Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt**](https://arxiv.org/abs/2406.04031) | Arxiv 2024 | 2024/05/14 | [Github](https://github.com/NY1024/BAP-Jailbreak-Vision-Language-Models-via-Bi-Modal-Adversarial-Prompt) | Encoder Level |
|[**Image Hijacks: Adversarial Images can Control Generative Models at Runtime**](https://arxiv.org/abs/2309.00236) | Arxiv 2024 | 2024 | [Github](https://github.com/euanong/image-hijacks) | Encoder Level |
|[**Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts**](https://arxiv.org/abs/2407.15050) | ACM MM 2024 | 2024 | None | Encoder Level |
|[**Are aligned neural networks adversarially aligned?**](https://arxiv.org/abs/2306.15447) | Arxiv 2023 | 2023 | None | Encoder Level |
|[**How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs**](https://arxiv.org/abs/2311.16101) | Arxiv 2023 | 2023 | [Github](https://github.com/UCSC-VLAA/vllm-safety-benchmark) | Encoder Level |
|[**Voice Jailbreak Attacks Against GPT-4o**](https://arxiv.org/abs/2405.19103) | Arxiv 2024 | 2024 | [Github](https://github.com/TrustAIRLab/VoiceJailbreakAttack) | Encoder Level |
|[**JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks**](https://arxiv.org/abs/2404.03027) | Arxiv 2024 | 2024 | [Github](https://eddyluo1232.github.io/JailBreakV28K/) | Encoder Level |
|[**Efficient LLM-Jailbreaking by Introducing Visual Modality**](https://arxiv.org/abs/2405.20015) | Arxiv 2024 | 2024 | None | Encoder Level |
|[**ImgTrojan: Jailbreaking Vision-Language Models with ONE Image**](https://arxiv.org/abs/2403.02910) | Arxiv 2024 | 2024 | [Github](https://github.com/xijia-tao/ImgTrojan) | Encoder Level |
|[**Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts**](https://arxiv.org/abs/2311.09127) | Arxiv 2023 | 2023 | None | Encoder Level |
|[**White-box Multimodal Jailbreaks Against Large Vision-Language Models**](https://arxiv.org/abs/2405.17894) | Arxiv 2023 | 2024 | None | Encoder Level |
|[**From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking**](https://arxiv.org/pdf/2406.14859v1) | Arxiv 2024 | 2024 | None | Encoder Level |
|[**Image-to-Text Logic Jailbreak: Your Imagination can Help You Do Anything**](https://arxiv.org/pdf/2407.02534) | Arxiv 2024 | 2024 | None | Encoder Level |
|[**Can Large Language Models Automatically Jailbreak GPT-4V?**](https://arxiv.org/pdf/2407.16686v2) | Arxiv 2024 | 2024 | None | Encoder Level |

## Jailbreak Attack of Multimodal Diffusion-based Models


## Jailbreak Attack of Any-to-Any Models
